[
["index.html", "Microbiome in R Exploring microbiome analysis using R Forewords", " Microbiome in R Exploring microbiome analysis using R Nabiilah Ardini Fauziyyah March 19, 2020 Forewords All praises be to Allah, The Beneficent and The Ever-Providing, who have given me the time, well-being, and intention to develop a companion book on Microbiome Study in R. This work is far from completed and will not be possible without the help many many friends and parties. With the hope of helping many people who ought to learn Microbiome Analysis as soon as possible, this work was published and will be continually updated. Microbiome Analysis is the analysis of a community of microorganisms (such as bacteria, fungi, and viruses) that inhabit a particular environment. The understanding of microbial community profiles from a specific environment, its dynamics, and clearer understanding of microbial role in the environment will provide us a huge lift on scientific discoveries and the initiation of further research for the improvement of human lives. With the development bioinformatics tools and package in R, microbiome analysis is getting more easier and accessible than ever. This book is made with the intention to bring microbiome analysis using R closer to you. You may be a data scientist with curiousity about microbiome or may be a biologist trying to learn new technology i.e. R to tackle your research project. This book hopefully shed a light on how microbiome analysis is performed, providing a comprehensive review and tutorial on the process of transforming microbiome raw data into valuable insight. Happy reading! "],
["microbiome-and-beyond.html", "Chapter 1 Microbiome and Beyond", " Chapter 1 Microbiome and Beyond Our earth has always been a home for billions of magnificent species that captivated the eye, including us. Every living thing occupies their respective habitat and evolves with it. But there are more than what is seen with the eyes! An abundant number of tiny organisms–even unseen to the naked eyes–has also been living with us all along. These tiny organisms are called microbes. Microbes are single-cell organisms that are approximately 1-5 micrometer in size, consisting of various species of bacteria and fungi (some said that viruses are also included). Although microbes are the smallest forms of life, they live in almost every place on earth, even inside our bodies. They have adapted to thrive in the normal and the most extreme condition on earth. Microbes live as a community and exchange various chemicals and nutrients that support their own growth and affect the ecosystem around them. For example, the oxygen we breathe in is the result of the past microbial activity of cyanobacteria from around 2.4 billion years ago, which risen the earth’s oxygen level and introduced what called as the great oxygenation event. Recent research also showed that a particular community of microbes lives inside our gut and can perform symbiotic relationships with us. It can secrete chemicals that boost our digestive system, prevent attack by harmful bacteria or viruses, program our immune system, and even direct our appetite, in exchange for a living space. In contrast, a particularly bad community of microbes can also live inside our gut and linked with a higher risk of several disorders including allergies, obesity, diabetes and many types of cancer (Sally Temraz 2019). This specific microbial community that lives in a particular environment is what we called as microbiome. The microbiome evolves as the environment evolves. This is why the microbiome has been linked with the ‘unseen’ force that supports and maintains the earth as well as the biological profile that describes that specific environment. Microbiome is often used to describe a specific condition of an environment. From our previous example, the gut microbiome profile can act as a biomarker for a healthy gut or a specific type of disease. The understanding of microbiome is also very powerful for environmental study. This study answers questions such as, What kind of community of microbes lives in a polluted river? What it consist of? In what way does each microbes from that community affect the environment they live in? Which microbes can act as a biomarker for polluted or unpolluted river? What actions that may recover or worsen the state of polluted river based on its microbial community (by utilizing the knowledge on microbial activity that may affect the environment), and so much more. The study that focuses on the discovery and the understanding of the microbiome is called Microbiome Analysis. It aims to discover microbial community profiles from a specific environment, understand the community dynamics in various conditions, and provide a clearer understanding of their role in the environment. In practice, this study often results in new findings for biomarkers that can be used to detect specific diseases or conditions in health and environmental studies. Further research may also open the door for the development of personalized diet or treatments! Microbiome analysis is one of the many topic that fall under the collaboration between Data Science and Biology. It envolves the processing of genetic data into pattern and visualization that we can gain insight from it. Although microbiome analysis is mainly focused on discovering patterns, it acts as a solid example of how explanatory data analysis can play a huge role in scientific discoveries and initiate further research for the improvement of human lives. In the next section, we will uncover what are the steps that build up a microbiome analysis and what is the idea behind them. "],
["microbiome-analysis-workflow.html", "Chapter 2 Microbiome Analysis Workflow 2.1 The Lab Work 2.2 Bioinformatic Analysis", " Chapter 2 Microbiome Analysis Workflow The workflow of microbiome analysis has evolved through out the years. The development of technology and Bioinformatics has made a massive increment on the generation of genomic data that is used for microbiome analysis. Therefore, the use of programming tools such as R and its packages is becoming more widely used. If I may put it into 2 major steps, microbiome analysis consist of “Lab Work” and “Bioinformatic Analysis” (Fig 2.1). The lab work of a microbiome analysis is quite plenty and mostly technical, which I will not explain it detail in here. Meanwhile, the bioinformatic analysis will be explained in this book with some tutorial. We will be using R languages and its packages as bioinformatics tools. 2.1 The Lab Work Every lab work of a microbiome analysis begins by taking a sample of microbial community from either soil, water, swab of a surface, saliva, or any other habitat. The microbes present in that sample will then be filtered and extracted for their DNA. Each microbial DNA will be sequenced to retrieve its genetic code, specifically in the region of a “fingerprint gene” called the 16S ribosomal RNA (16S rRNA). For those of you who are not familiar with cell and molecular biology, these are a brief explanation. DNA is a molecule that harbors genes or sequences of genetic code of a living things. This DNA can be used as a taxonomic marker that differentiate each microbial species from one another. A specific region of DNA called the 16S rRNA gene is usually used for comparation, for this gene exist in all of microbes but has slightly different sequence for each microbes. The difference between each sequence will be calculated to determine how distant or related a microbial species with one another. 2.2 Bioinformatic Analysis After we have the sequencing result, the bioinformatic analysis can be performed. In brief, this steps aims to compare the sample DNA sequences to the annotated DNA sequences in biological database (ie. GenBank or personal database). This is done through alignment of those sequences and the construction of phylogenetic tree aka. the tree of life. Unknown DNA sample will be identified based on its most related species from the database, on condition that the DNA similarity reached a certail treshold. After all microbes from the community has been identified, we can analyze the community structure and diversity by calculating the abundance of each microbes. We will able to know which microbes dominates over the other, what microbial activities it can do that may affect the environment being studied, etc. This microbial community profile will help us understand the phenomenon happen in a specific environment. We may even discover potential biomarker for industrial application. From the technical side, the steps of bioinformatic analysis starts from the dirty data cleaning, performing some data pre-processing, followed by applying some algorithms, and finalized by some data visualization and extracting valuable insight. Below is the summary of Bioconductor Workflow for Microbiome Data Analysis adapted from Ben J. Callahan (2016). Bioconductor is a repositories of open source software for Bioinformatics, based on packages written primarily in the R programming language. Amplicon bioinformatics: Data Cleaning Trimming and Filtering Infer Sequence Variants Merge Forward-Reverse DNA Sequences Construct Sequence Table &amp; Remove Chimeras Amplicon Bioinformatics: Phylogenetic Analysis Assign Taxonomy Construct Phylogenetic Tree Combine data into Phylosec Object Microbiome analysis: community structure, abundance, and diversity Microbiome analysis: community profile visualization using PCA Microbiome analysis: Supervised learning Microbiome analysis: graph analysis using network visualization We will discuss deeper for each steps of microbiome analysis and the packages related to it in the following section. A tutorial installing Bioconductor packages also provided in the next section, for it is slightly different than what we usually do when installing packages from CRAN. "],
["bioconductor-installation.html", "Chapter 3 Bioconductor Installation", " Chapter 3 Bioconductor Installation Numerous packages for bioinformatics analysis stored in Bioconductor repository. The current release of Bioconductor is version 3.10 and works with R version 3.6.0. Users of older R and Bioconductor must update their installation to take advantage of new features and to access packages that have been added to Bioconductor since the last release (Bioconductor 2020). Install the latest version of Bioconductor by entering the commands below: if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) # progress &amp; error suppressed install.packages(&quot;BiocManager&quot;) BiocManager::install(version = &quot;3.10&quot;) In additition, if you see the following messege during installation: That’s its way to notice you that there are some packages (usually from CRAN repository) that is out-of-date. You can type a in the console to install the latest updates or any other option available (some or none). You may also install the latest updates manually from the ‘Packages’ panel. To install specific packages from Bioconductor, use the following commands: # packages for microbiome analysis BiocManager::install(c(&quot;dada2&quot;, &quot;phyloseq&quot;, &quot;DECIPHER&quot;, &quot;phangorn&quot;)) Now, many have questioned why there is a need to use BiocManager::install() to install packages from Bioconductor. This is because Bioconductor has a repository and release schedule that differs from R. A consequence of the mismatch between R and Bioconductor release schedules is that the Bioconductor version identified by install.packages() is sometimes not the most recent ‘release’ available. The BiocManager package serves as the primary way to ensure that the appropriate Bioconductor installation is used with respect to the version of R in use regardless of the R and Bioconductor release cycles (Bioconductor 2020). For further documentation of the installation of Bioconductor, click here. "],
["amplicon-bioinformatics-data-cleaning.html", "Chapter 4 Amplicon Bioinformatics: Data Cleaning 4.1 Libraries 4.2 Dataset 4.3 Trimming &amp; Filtering 4.4 Infer Sequence Variants 4.5 Merging Forward &amp; Reverse DNA Sequences 4.6 Construct Sequence Table &amp; Remove Chimeras", " Chapter 4 Amplicon Bioinformatics: Data Cleaning This section demonstrates the first step of performing microbiome analysis in R. Amplicon bioinformatics is the steps of how we prepare a raw data into format needed for analysis. The steps include construction of the raw reads from sequencing result into the table we ought to analyze. Below is an illustration of what we are going to do in amplicon bioinformatics especially for the data cleaning part (Fig 4.1). 4.1 Libraries First, we should load the necessary packages. You might also want to install some packages if you haven’t installed them to your machine. # install packages BiocManager::install(&quot;BiocStyle&quot;) # libraries library(knitr) # for reporting library(ggplot2) # for graph visualization library(tidyverse) library(gridExtra) # additional mapping for ggplot2 library(BiocStyle) library(dada2) library(phyloseq) library(DECIPHER) library(phangorn) 4.2 Dataset The dataset for microbiome analysis is usually a set of raw reads of DNA sequences a.k.a. amplicons stored in a digital format as a result of DNA sequencing method performed in labs. The DNA of a microbial species needs to be sequenced first to retrieve its information and store it in a digitalized form. There are various tools for DNA sequencing with the Next Generation Sequencing (NGS) technology being commonly used today. It allows rapid sequencing for a massive load of DNA sequences. You are free to use your own amplicons dataset while following the tutorial provided in this book. Meanwhile, if you don’t have one, you can use the data provided free in here. The data is also used on the original “Bioconductor Workflow for Microbiome Data Analysis”. The data consisted of amplicons from the V4 region of the 16S rRNA gene sequenced through Illumina Miseq NGS technology. The V4 region stands for the more specific region of the 16S rRNA gene, the “fingerprint gene” which we will use to explain the identity of microbial species inside the community we ought to analyze. The data contains DNA samples of microbial communities from a 360 fecal samples, collected from 12 mice over the first year of life. This samples were investigated for analyzing the development and stabilization of the murine microbiome (PD Schloss 2012). These are the steps for reading the data: The data can be downloaded in the link provided above. The data will be in .tar format. It stands for Tape Archive or Consolidated Unix Archive format. You will need to extract it to obtain the amplicons in .fastq.gz stands for gzip compressed archive format. There will be 724 files consisted of: 360 forward reads of community DNA samples 360 reverse reads of community DNA samples 2 forward reads of control (mock) samples 2 reverse reads of control (mock) samples For those of you who are interested in understanding more about the sample it is a good idea to read the original research publication and perhaps also articles about designing an experiment including its control. The amplicons are stored with a standard naming system with an “R1” and \"R2 label as forward and reverse reads respectively. Forward and reverse reads came from the sequencing method itself which sequenced DNA in two direction just as illustrated in Fig 4.1. Here is a great video about DNA sequencing for more detailed process. Before further analysis, forward and reverse reads of DNA need to be “cleaned” first for its low quality reads and then joined to obtain the full DNA. The data cleaning process is called Trimming and Filtering which we will discuss in the next section. Below, the amplicons will be tagged for data cleaning process. The amplicons are still in its compressed format but luckily most bioinformatics tools have the ability to process the compressed files. This is quite a convenience as most microbiome analysis deals with large-sized data and compressed files are, well, more “compressed”. The code below will try to list all the amplicons stored in our working directory and separate them between the reverse or forward reads for the data cleaning process. # list all sequence files amplicons &lt;- sort(list.files(path = &quot;data/miseq&quot;, # location of your amplicon files full.names = TRUE)) head(amplicons) ## [1] &quot;data/miseq/F3D0_S188_L001_R1_001.fastq.gz&quot; ## [2] &quot;data/miseq/F3D0_S188_L001_R2_001.fastq.gz&quot; ## [3] &quot;data/miseq/F3D1_S189_L001_R1_001.fastq.gz&quot; ## [4] &quot;data/miseq/F3D1_S189_L001_R2_001.fastq.gz&quot; ## [5] &quot;data/miseq/F3D11_S198_L001_R1_001.fastq.gz&quot; ## [6] &quot;data/miseq/F3D11_S198_L001_R2_001.fastq.gz&quot; # search for a pattern in the list # R1 = DNA forward sequences; R2 = DNA reverse sequences amplicons_F &lt;- amplicons[grepl(&quot;R1&quot;, amplicons)] amplicons_R &lt;- amplicons[grepl(&quot;R2&quot;, amplicons)] 4.3 Trimming &amp; Filtering After we have separate the sequences into reverse/forward, we need to perform data cleaning by trimming &amp; filtering. Raw reads are often have regions with low-quality reads. Most Illumina sequencing data shows a trend of decreasing average quality towards the end of sequencing reads (Ben J. Callahan 2016). To know which regions have low quality reads, we can plot it using plotQualityProfile() from dada2 package for amplicon analysis. This function plots a visual summary of the distribution of quality scores for each sequence position. For more clarity, one amplicon files consist of numerous DNA sequences from each microbial present in one community sample. Each sequences calculated for its quality score in each sequence position (first to last). The plot will generate the summary of quality score from all the DNA sequences in one sample. Let’s take the first 3 observation and plot its reverse and forward reads for its quality profile. From there we can determine which position with low quality reads and trim them later. # plotting 1st observation f_plot &lt;- plotQualityProfile(amplicons_F[1:3]) + labs(x = &quot;Sequence Position&quot;) r_plot &lt;- plotQualityProfile(amplicons_R[1:3]) + labs(x = &quot;Sequence Position&quot;) grid.arrange(f_plot,r_plot,ncol = 1) The distribution of quality scores at each sequence position is shown as a grey-scale heatmap. The darker color represent higher frequency of each quality score at each sequence position. Notice that I’ve intentionally changed the x label for easier interpretation. It also shown the quality score summary: green line: mean quality score orange line-solid: median quality score orange line-dashed: 25th and 75th quantiles Reads: number of reads (DNA sequences present in a sample) red line: scaled proportion of reads that extend to at least that position (this is more useful for other sequencing technologies, as Illumina reads are typically all the same length, hence resulting a flat red line). The forward reads are in good quality, but it is still better to trim a few of the first/last position of a sequence to avoid errors that can arise there. In this example, we will trim the first 10 positions because based on empirical observations across many Illumina datasets, the first or last 10 positions are particularly likely to contain pathological errors (Ben J. Callahan 2016). Meanwhile, the reverse reads are more worse in quality, especially at the end. From the plot result, we will trim the last 160 positions from the reverse reads. After determining the trimming position for each forward &amp; reverse reads, we will combine it with the standard filtering parameters maxEE = 2 (the maximum number of expected errors allowed in a read is 2)(Ben J. Callahan 2016). Trimming and filtering is performed on paired reads jointly, i.e. both reads must pass the filter for the pair to pass. In the code below, we first create a file path for our filtered reads in the working directory and then perform the trimming and filtering. # creating file path for filtered reads filtered_path &lt;- file.path(&quot;data&quot;, &quot;filtered&quot;) # path: &quot;data/filtered&quot; if(!file_test(&quot;-d&quot;, filtered_path)) #&quot;if there is no directory `filt_path`, dir.create(filtered_path) # &quot;create one&quot; # prepare the file path for each filtered read filtered_F &lt;- file.path(filtered_path, basename(amplicons_F)) filtered_R &lt;- file.path(filtered_path, basename(amplicons_R)) # check the file path head(filtered_F, 3) ## [1] &quot;data/filtered/F3D0_S188_L001_R1_001.fastq.gz&quot; ## [2] &quot;data/filtered/F3D1_S189_L001_R1_001.fastq.gz&quot; ## [3] &quot;data/filtered/F3D11_S198_L001_R1_001.fastq.gz&quot; # trimming &amp; filtering for(i in seq_along(amplicons_F)) { fastqPairedFilter(c(amplicons_F[[i]], amplicons_R[[i]]), # input: raw amplicons c(filtered_F[[i]], filtered_R[[i]]), # output: amplicons after trimming &amp; filtering # trimming trimLeft=10, # trim the first n observation from each reads truncLen=c(245,160), # truncate reads after this position; c(Forward/Reverse) # filtering maxN=0, maxEE=2, truncQ=2, # max expected error (MEE) = 2 # additional setting compress=TRUE) # whether the output should be compressed } Wait for a while as your machine processing your request to trim and filter the amplicons. When it is done, the resulting amplicons will be located in the filtered_path you have stated earlier. 4.4 Infer Sequence Variants After filtering, typical workflow will continue to perform clustering of the DNA sequences into Operational Taxonomic Units (OTUs) or the estimated distinct species present in the community. This is performed by creating groups of sequencing reads that differ by less than a fixed dissimilarity threshhold. Even so, there is still a possibility of sequencing errors generating artificial sequences. To tackle this problem, a high-throughput DADA2 method was developed. This method can infer amplicon sequence variants (ASVs) from our amplicons data. ASVs are individual DNA sequences recovered after the removal of false sequences generated from error during PCR amplification and sequencing. ASVs are considered as the true biological sequences and therefore will be used for further analysis. DADA2 works by making use of a parametric error model err to distinguish between true biological sequences (ASVs) and those generated by error Ben J. Callahan (2016). This error model learns the maximum possible error rates of our amplicons data using the learnErrors() function. The error model will later be used in the DADA2 algorithm using dada() function. The following code was adapted from DADA2 pipeline tutorial for dada2 v1.12 (Callahan, n.d.) for the more updated version. # error model for forward reads error_F &lt;- learnErrors(filtered_F) #input: file path for filtered reads # error model for reverse reads error_R &lt;- learnErrors(filtered_R) #infer sequence variants dada_F &lt;- dada(filtered_F, err = error_F, verbose = 0) # verbose = 0; no text output for 362 samples dada_R &lt;- dada(filtered_R, err = error_R, verbose = 0) 4.5 Merging Forward &amp; Reverse DNA Sequences The DADA2 algorithm removed (nearly) all substitution errors from the data and the data are now ready to be merged. merged &lt;- mergePairs(dadaF = dada_F, # dada result derepF = filtered_F, # path of filtered reads dadaR = dada_R, derepR = filtered_R) 4.6 Construct Sequence Table &amp; Remove Chimeras Using the merged pairs of the amplicon data, a sequence table or in this case an amplicon sequence variant (ASV) table can be generated. This table is in matrix format with rows stores the sample names and the columns stores the number of each ASVs. From this table we can inspect the number of ASVs (representing each microbial species) in each sample. ASV table is a higher-resolution version of the OTU table produced by tradisional method. We can construct a sequence table using makeSequenceTable(). seqtab &lt;- makeSequenceTable(merged) Below is a glimpse of what our seqtab matrix looks like: # first 3 observation; first 3 ASV (named by its DNA sequence) seqtab[1:3,1:3] ## GCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGTGCGCAGGCGGAAGATCAAGTCAGCGGTAAAATTGAGAGGCTCAACCTCTTCGAGCCGTTGAAACTGGTTTTCTTGAGTGAGCGAGAAGTATGCGGAATGCGTGGTGTAGCGGTGAAATGCATAGATATCACGCAGAACTCCGATTGCGAAGGCAGCATACCGGCGCTCAACTGACGCTCATGCACGAAAGTGTGGGTATC ## F3D0_S188_L001_R1_001.fastq.gz 582 ## F3D1_S189_L001_R1_001.fastq.gz 416 ## F3D11_S198_L001_R1_001.fastq.gz 3193 ## GCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGTGCGCAGGCGGACTCTCAAGTCAGCGGTCAAATCGCGGGGCTCAACCCCGTTCCGCCGTTGAAACTGGGAGCCTTGAGTGCGCGAGAAGTAGGCGGAATGCGTGGTGTAGCGGTGAAATGCATAGATATCACGCAGAACTCCGATTGCGAAGGCAGCCTACCGGCGCGCAACTGACGCTCATGCACGAAAGCGTGGGTATC ## F3D0_S188_L001_R1_001.fastq.gz 341 ## F3D1_S189_L001_R1_001.fastq.gz 353 ## F3D11_S198_L001_R1_001.fastq.gz 1817 ## GCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGTGCGTAGGCGGGCTGTTAAGTCAGCGGTCAAATGTCGGGGCTCAACCCCGGCCTGCCGTTGAAACTGGCGGCCTCGAGTGGGCGAGAAGTATGCGGAATGCGTGGTGTAGCGGTGAAATGCATAGATATCACGCAGAACTCCGATTGCGAAGGCAGCATACCGGCGCCCGACTGACGCTGAGGCACGAAAGCGTGGGTATC ## F3D0_S188_L001_R1_001.fastq.gz 448 ## F3D1_S189_L001_R1_001.fastq.gz 232 ## F3D11_S198_L001_R1_001.fastq.gz 2054 dim(seqtab) ## [1] 362 684 We have a total of maximum 684 ASVs or expected microbial species that may present in a community sample. The last data cleaning step that we can do is to remove chimeras. Chimeras are DNA sequences which are formed from 2 or more biological sequences joined together (Fig 4.2). These chimeras can act as distinct microbial species alone when in fact it is not a true microbial sequences. FIG 4.2 [chimeras] Chimeras can be identified if they can be exactly reconstructed by combining a left-segment and a right-segment from two more abundant “parent” or biological sequences. We can remove chimeras using function removeBimeraDenovo(). seqtab_nochim &lt;- removeBimeraDenovo(seqtab, method = &quot;consensus&quot;, multithread = FALSE) dim(seqtab_nochim) ## [1] 362 419 sum(seqtab_nochim)/sum(seqtab) ## [1] 0.9621193 Removing chimeras leave us with 419 ASVs from the original 684 ASVs we previously have. Even so, if you calculate the percentage of chimeric sequences from the total abundance of all sequences, it only accounts for 4% of the data. This amount is small and acceptable. On the other hand, if your analysis indicates a lot of chimeric sequences there might be some upstream processes that have gone wrong such as not removing the primer sequences from the fasta prior to reading the data Callahan (n.d.). As an additional final steps for amplicon bioinformatics: data cleaning process, you can track the number of reads or sequences that made it through each step of the processes by making your own function. But I’ll leave it out to you for further exploration in the detailed DADA2 1.12 Pipeline Tutorial. "]
]

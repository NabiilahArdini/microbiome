[
["index.html", "Microbiome in R Exploring microbiome analysis using R Chapter 1 Forewords", " Microbiome in R Exploring microbiome analysis using R Nabiilah Ardini Fauziyyah June 19, 2020 Chapter 1 Forewords All praises be to Allah, The Beneficent and The Ever-Providing, who have given me the time, well-being, and intention to develop a companion book on Microbiome Study in R. This work is far from completed and will not be possible without the help many many friends and parties. With the hope of helping many people who ought to learn Microbiome Analysis as soon as possible, this work was published and will be continually updated. Microbiome Analysis is the analysis of a community of microorganisms (such as bacteria, fungi, and viruses) that inhabit a particular environment. The understanding of microbial community profiles from a specific environment, its dynamics, and clearer understanding of microbial role in the environment will provide us a huge lift on scientific discoveries and the initiation of further research for the improvement of human lives. With the development bioinformatics tools and package in R, microbiome analysis is getting more easier and accessible than ever. This book is made with the intention to bring microbiome analysis using R closer to you. You may be a data scientist with curiousity about microbiome or may be a biologist trying to learn new technology i.e. R to tackle your research project. This book hopefully shed a light on how microbiome analysis is performed, providing a comprehensive review and tutorial on the process of transforming microbiome raw data into valuable insight. Happy reading! "],
["microbiome-and-beyond.html", "Chapter 2 Microbiome and Beyond", " Chapter 2 Microbiome and Beyond Our earth has always been a home for billions of magnificent species that captivated the eye, including us. Every living thing occupies their respective habitat and evolves with it. But there are more than what is seen with the eyes! An abundant number of tiny organisms–even unseen to the naked eyes–has also been living with us all along. These tiny organisms are called microbes. Microbes are single-cell organisms that are approximately 1-5 micrometer in size, consisting of various species of bacteria and fungi (some said that viruses are also included). Although microbes are the smallest forms of life, they live in almost every place on earth, even inside our bodies. They have adapted to thrive in the normal and the most extreme condition on earth. Microbes live as a community and exchange various chemicals and nutrients that support their own growth and affect the ecosystem around them. For example, the oxygen we breathe in is the result of the past microbial activity of cyanobacteria from around 2.4 billion years ago, which risen the earth’s oxygen level and introduced what called as the great oxygenation event. Recent research also showed that a particular community of microbes lives inside our gut and can perform symbiotic relationships with us. It can secrete chemicals that boost our digestive system, prevent attack by harmful bacteria or viruses, program our immune system, and even direct our appetite, in exchange for a living space. In contrast, a particularly bad community of microbes can also live inside our gut and linked with a higher risk of several disorders including allergies, obesity, diabetes and many types of cancer (Sally Temraz 2019). This specific microbial community that lives in a particular environment is what we called as microbiome. The microbiome evolves as the environment evolves. This is why the microbiome has been linked with the ‘unseen’ force that supports and maintains the earth as well as the biological profile that describes that specific environment. The study that focuses on the discovery and the understanding of the microbiome is called Microbiome Analysis. It aims to discover microbial community profiles from a specific environment, understand the community dynamics in various conditions, and provide a clearer understanding of their role in the environment. The understanding of microbiome is very powerful for health/environmental study. It answers questions such as, Which community of microbes lives in the gut of a healthy person? Are there any microbes that can act as a biomarker for healthy/ill person? Expanding the knowledge obtained from the study, scientist can create new questions for further study such as, In what way does each microbe affect the environment they live in? What actions that may recover or worsen the state of an environment, based on its microbiome? (supported with the knowledge on chemical process that it performs) In practice, the understanding of microbiome can leads to the discovery of biomarkers, a certain species that can be used to detect specific diseases or conditions in health and environmental studies. There is always a possibility to utilize microbiome data for classification case in machine learning and AI. Further research may also open the door for the development of personalized treatments based on microbiome profile! Microbiome analysis is one of the many topic that fall under the collaboration between Data Science and Biology. It envolves the processing of genetic data into pattern and visualization that we can gain insight from it. Although microbiome analysis is mainly focused on explanatory data analysis (EDA), it acts as a solid example of how EDA can play a huge role in scientific discoveries and initiate further research for the improvement of human lives. In the next chapter, we will uncover what are the steps that build up a microbiome analysis and what is the idea behind them. "],
["microbiome-analysis-workflow.html", "Chapter 3 Microbiome Analysis Workflow 3.1 The Lab Work 3.2 Bioinformatic Analysis", " Chapter 3 Microbiome Analysis Workflow The workflow of microbiome analysis has evolved through out the years. The development of technology and Bioinformatics has made a massive increment on the generation of genomic data that is used for microbiome analysis. Therefore, the use of programming tools such as R and its packages is becoming more widely used. If I may put it into 2 major steps, microbiome analysis consist of “Lab Work” and “Bioinformatic Analysis”. The lab work of a microbiome analysis is quite plenty and mostly technical, which I will not explain it detail in here. Meanwhile, the bioinformatic analysis will be explained in this book with some tutorial. We will be using R languages and its packages as bioinformatics tools. 3.1 The Lab Work Every lab work of a microbiome analysis begins by taking a sample of microbial community from either soil, water, swab of a surface, saliva, or any other habitat. The microbes present in that sample will then be filtered and extracted for their DNA. Each microbial DNA will be sequenced to retrieve its genetic code, specifically in the region of a “fingerprint gene” called the 16S ribosomal RNA (16S rRNA). The process briefly explained in the illustration below (Fig 2.1). For those of you who are not familiar with cell and molecular biology, these are a brief explanation. DNA is a molecule that harbors genes or sequences of genetic code of a living things. This DNA can be used as a taxonomic marker that differentiate each microbial species from one another. A specific region of DNA called the 16S rRNA gene is usually used for comparation, for this gene exist in all of microbes but has slightly different sequence for each microbes. The difference between each sequence will be calculated to determine how distant or related a microbial species with one another. 3.2 Bioinformatic Analysis After we have the sequencing result, the bioinformatic analysis can be performed. The steps consist of assigning taxonomy or giving identity to the unknown DNA samples and analysis of the their community structure and dynamics. We can analyze the community structure and dynamics by calculating the diversity and abundance of each microbes present in the samples. We will able to know which microbes dominates over the other, what microbial activities it can do that may affect the environment being studied, etc. This microbial community profile will help us understand the phenomenon happen in a specific environment. We may even discover potential biomarker for industrial application. From the technical side, the steps of bioinformatic analysis starts from the dirty data cleaning, performing some data pre-processing, followed by applying some algorithms, and finalized by some data visualization and extracting valuable insight. Below is the summary of Bioconductor Workflow for Microbiome Data Analysis adapted from Ben J. Callahan (2016) and several documentation from updated packages commonly used for microbiome analysis. Bioconductor itself is a repositories of open source software for Bioinformatics, based on packages written primarily in the R programming language. Amplicon Bioinformatics: from raw reads to table. Phyloseq Object Processing: pre-processing of sequence data in phyloseq format. Microbiome Data Analysis: data exploration using common plots and PCoA. Classification Problem on Microbiome Data [Additional] We will discuss deeper for each steps of microbiome analysis and the packages related to it in the following chapter. A tutorial installing Bioconductor packages also provided in the next chapter, for it is slightly different than what we usually do when installing packages from CRAN. "],
["bioconductor-installation.html", "Chapter 4 Bioconductor Installation", " Chapter 4 Bioconductor Installation Numerous packages for bioinformatics analysis stored in Bioconductor repository. The current release of Bioconductor is version 3.10 and works with R version 3.6.0. Users of older R and Bioconductor must update their installation to take advantage of new features and to access packages that have been added to Bioconductor since the last release (Bioconductor 2020). Install the latest version of Bioconductor by entering the commands below: if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) # progress &amp; error suppressed install.packages(&quot;BiocManager&quot;) BiocManager::install(version = &quot;3.10&quot;) In additition, if you see the following messege during installation: That’s its way to notice you that there are some packages (usually from CRAN repository) that is out-of-date. You can type a in the console to install the latest updates or any other option available (some or none). You may also install the latest updates manually from the ‘Packages’ panel. To install specific packages from Bioconductor, use the following commands: # packages for microbiome analysis BiocManager::install(c(&quot;BiocStyle&quot;, &quot;dada2&quot;, &quot;phyloseq&quot;, &quot;DECIPHER&quot;, &quot;phangorn&quot;)) Now, many have questioned why there is a need to use BiocManager::install() to install packages from Bioconductor. This is because Bioconductor has a repository and release schedule that differs from R. A consequence of the mismatch between R and Bioconductor release schedules is that the Bioconductor version identified by install.packages() is sometimes not the most recent ‘release’ available. The BiocManager package serves as the primary way to ensure that the appropriate Bioconductor installation is used with respect to the version of R in use regardless of the R and Bioconductor release cycles (Bioconductor 2020). For further documentation of the installation of Bioconductor, click here. "],
["amplicon-bioinformatics.html", "Chapter 5 Amplicon Bioinformatics 5.1 Libraries 5.2 Dataset 5.3 Trimming &amp; Filtering 5.4 Infer Sequence Variants 5.5 Merge Forward &amp; Reverse Reads 5.6 Construct Sequence Table &amp; Remove Chimeras 5.7 Assign Taxonomy 5.8 Construct Phylogenetic Tree 5.9 Create Phyloseq Object", " Chapter 5 Amplicon Bioinformatics This chapter demonstrates the first step of performing microbiome analysis in R. Amplicon bioinformatics include construction of the raw reads from sequencing result into the table we ought to analyze. Below is an illustration of what we are going to do in amplicon bioinformatics (Fig 4.1). 5.1 Libraries First, we should load the necessary packages. You might also want to install some packages if you haven’t installed them to your machine. # CRAN libraries library(tidyverse) # for data cleaning/wrangling library(ggplot2) # for visualization # Bioconductor libraries library(dada2) library(phyloseq) library(Biostrings) library(DECIPHER) library(phangorn) We will be using a lot of functions from DADA2 package for amplicon analysis and therefore I will be following DADA2 Pipeline Tutorial (1.12) (Callahan, n.d.). Through out the tutorial, I will try to explain each step in hopefully a more friendly manner for people who are new to this analysis. 5.2 Dataset The dataset for microbiome analysis is usually a set of raw reads of DNA sequences a.k.a. amplicons stored in a digital format as a result of DNA sequencing method performed in labs. The DNA of a microbial species needs to be sequenced first to retrieve its information and store it in a digitalized form. There are various tools for DNA sequencing with the Next Generation Sequencing (NGS) technology being commonly used today. It allows rapid sequencing for a massive load of DNA sequences simultaneously. You are free to use your own amplicons dataset while following the tutorial provided in this book. But please do notice that the data should met certain criteria as follows: Samples have been demultiplexed, i.e. each samples have their own DNA sequence (.fastq file). Non-biological sequences have been removed, i.e. the samples are free of primers and other artificial sequences from lab work processes. If paired-end sequencing data, the forward and reverse .fastq files contain reads in matched order. Meanwhile, if you don’t have one, you can use the mothur MiSeq SOP data provided free in here. The data is also used on the original tutorial. The data consisted of amplicons from the V4 region of the 16S rRNA gene sequenced through Illumina Miseq NGS technology. The V4 region stands for the more specific region of the 16S rRNA gene. The data contains DNA from microbial communities collected from gut samples of a mice during post weaning growth (after milk diet). The original experiment were done with the aim to understand the effect of normal gut microbiome to the mice health. The full data is extremely large to process for this introductionary phase (3.9 GB) and therefore we will be using only parts of the data. With the available data we have, let’s try to understand the effect of the first 10 days of post weaning (eating) period to the stability of gut microbiome in the 140-150 day of post weaning period. These are the steps for reading the data: The data can be downloaded in the link provided above. The data will be in .zip format. You will need to extract it to obtain the amplicons in .fastq format and some additional files. There will be 45 files consisted of: 19 forward reads of community DNA samples 19 reverse reads of community DNA samples 1 forward reads of control (mock) samples 1 reverse reads of control (mock) samples 1 HMP_mock.v35 fasta (annotated (named) DNA from mock samples) 5 additional information files: mouse.dwp.metadata mouse.time.design stability.batch stability files For those of you who are interested in understanding more about the sample it is a good idea to read the original research publication and perhaps also articles about designing an experiment including its control. The DNA samples or amplicons are stored with a standard naming system: F3D0 stands for the mice id F3 and the day of sampling D0 the R1 and R2 stands for forward and reverse reads respectively. Forward and reverse reads came from the sequencing method which sequenced DNA in two direction just as illustrated in Fig 4.1. Here is a great video about DNA sequencing for more detailed process. Before further analysis, forward and reverse reads of DNA need to be “cleaned” first for its low quality reads and then joined to obtain the full DNA. The data cleaning process is called Trimming and Filtering which we will discuss in the next section. Below, the amplicons will be tagged for data cleaning process. The amplicons may still be in its compressed format (.fastq.gz) but the one we have are not. For those of you who have the compressed format, luckily most bioinformatics tools have the ability to process even the compressed files. This is quite a convenience as most microbiome analysis deals with large-sized data and compressed files are, well, more “compressed”. The code below will try to list all the amplicons stored in our working directory and separate them between the reverse or forward reads for the data cleaning process. # list amplicons into forward/reverse reads amplicons_F &lt;- sort(list.files(path = &quot;data/MiSeq_SOP&quot;, # location of your amplicons pattern = &quot;R1&quot;, # forward reads full.names = TRUE)) amplicons_R &lt;- sort(list.files(path = &quot;data/MiSeq_SOP&quot;, pattern = &quot;R2&quot;, # reverse reads full.names = TRUE)) # check the first 6 data head(amplicons_F) ## [1] &quot;data/MiSeq_SOP/F3D0_S188_L001_R1_001.fastq&quot; ## [2] &quot;data/MiSeq_SOP/F3D1_S189_L001_R1_001.fastq&quot; ## [3] &quot;data/MiSeq_SOP/F3D141_S207_L001_R1_001.fastq&quot; ## [4] &quot;data/MiSeq_SOP/F3D142_S208_L001_R1_001.fastq&quot; ## [5] &quot;data/MiSeq_SOP/F3D143_S209_L001_R1_001.fastq&quot; ## [6] &quot;data/MiSeq_SOP/F3D144_S210_L001_R1_001.fastq&quot; head(amplicons_R) ## [1] &quot;data/MiSeq_SOP/F3D0_S188_L001_R2_001.fastq&quot; ## [2] &quot;data/MiSeq_SOP/F3D1_S189_L001_R2_001.fastq&quot; ## [3] &quot;data/MiSeq_SOP/F3D141_S207_L001_R2_001.fastq&quot; ## [4] &quot;data/MiSeq_SOP/F3D142_S208_L001_R2_001.fastq&quot; ## [5] &quot;data/MiSeq_SOP/F3D143_S209_L001_R2_001.fastq&quot; ## [6] &quot;data/MiSeq_SOP/F3D144_S210_L001_R2_001.fastq&quot; # extract sample names sample_names &lt;- basename(amplicons_F) %&gt;% # get file names word(start = 1L, sep = &quot;_&quot;) # get the first word as the sample names head(sample_names) ## [1] &quot;F3D0&quot; &quot;F3D1&quot; &quot;F3D141&quot; &quot;F3D142&quot; &quot;F3D143&quot; &quot;F3D144&quot; 5.3 Trimming &amp; Filtering After we have separate the sequences into reverse/forward, we need to perform data cleaning by trimming &amp; filtering. Raw reads are often have regions with low-quality reads. Most Illumina sequencing data shows a trend of decreasing average quality towards the end of sequencing reads (Ben J. Callahan 2016). To know which regions have low quality reads, we can plot it using plotQualityProfile() from DADA2 package. This function plots a visual summary of the distribution of quality scores for each sequence position. For more clarity, one amplicon files consist of numerous DNA sequences from each microbial present in one community sample. Each sequences calculated for its quality score in each sequence position (first to last). The plot will generate the summary of quality score from all the DNA sequences in one sample. Let’s take the first 3 observation and plot its reverse and forward reads for its quality profile. From there we can determine which position with low quality reads and trim them later. # plotting 1st observation f_plot &lt;- plotQualityProfile(amplicons_F[1:3]) + labs(x = &quot;Sequence Position&quot;) r_plot &lt;- plotQualityProfile(amplicons_R[1:3]) + labs(x = &quot;Sequence Position&quot;) grid.arrange(f_plot,r_plot,ncol = 1) The distribution of quality scores at each sequence position is shown as a grey-scale heatmap. The darker color represent higher frequency of each quality score at each sequence position. Notice that I’ve intentionally changed the x label for easier interpretation. It also shown the quality score summary: green line: mean quality score orange line-solid: median quality score orange line-dashed: 25th and 75th quantiles Reads: number of reads (DNA sequences present in a sample) red line: scaled proportion of reads that extend to at least that position (this is more useful for other sequencing technologies, as Illumina reads are typically all the same length, hence resulting a flat red line). The forward reads are in good quality, but it is still better to trim a few of the first/last position of a sequence to avoid errors that can arise there. In this example, we will trim the first 10 positions because based on empirical observations across many Illumina datasets, the first or last 10 positions are particularly likely to contain pathological errors (Ben J. Callahan 2016). Meanwhile, the reverse reads are more worse in quality, especially at the end. From the plot result, we will trim the last 160 positions from the reverse reads. After determining the trimming position for each forward &amp; reverse reads, we will combine it with the standard filtering parameters maxEE = 2 (the maximum number of expected errors allowed in a read is 2)(Ben J. Callahan 2016). Trimming and filtering is performed on paired reads jointly, i.e. both reads must pass the filter for the pair to pass. In the code below, we first create a file path for our filtered reads in the working directory and then perform the trimming and filtering. # creating directory for filtered reads if(!file_test(&quot;-d&quot;, &quot;data/filtered&quot;)) #&quot;if there is no directory `data/filtered`, dir.create(&quot;data/filtered&quot;) # &quot;create one&quot; # creating file path # &quot;data/filtered/sample_names_*_filtered.fastq.gz&quot; filtered_F &lt;- file.path(&quot;data&quot;, &quot;filtered&quot;, paste0(sample_names,&quot;_F_filtered.fastq.gz&quot;)) filtered_R &lt;- file.path(&quot;data&quot;, &quot;filtered&quot;, paste0(sample_names,&quot;_R_filtered.fastq.gz&quot;)) # check the file path head(filtered_F, 3) ## [1] &quot;data/filtered/F3D0_F_filtered.fastq.gz&quot; ## [2] &quot;data/filtered/F3D1_F_filtered.fastq.gz&quot; ## [3] &quot;data/filtered/F3D141_F_filtered.fastq.gz&quot; # trimming &amp; filtering tnf_summary &lt;- filterAndTrim(amplicons_F, filtered_F, # input and output amplicons_R, filtered_R, # trimming trimLeft=10, # trim the first n observation from each reads truncLen=c(240,160), # truncate reads after this position; c(Forward/Reverse) # filtering standard maxN=0, maxEE=c(2,2), # max expected error (maxEE) = 2 truncQ=2, rm.phix=TRUE, # additional setting compress=TRUE, # whether outputs should be compressed multithread=FALSE) # default for Windows, Mac can use `multithread=TRUE` tnf_summary ## reads.in reads.out ## F3D0_S188_L001_R1_001.fastq 7793 7139 ## F3D1_S189_L001_R1_001.fastq 5869 5314 ## F3D141_S207_L001_R1_001.fastq 5958 5478 ## F3D142_S208_L001_R1_001.fastq 3183 2926 ## F3D143_S209_L001_R1_001.fastq 3178 2955 ## F3D144_S210_L001_R1_001.fastq 4827 4323 ## F3D145_S211_L001_R1_001.fastq 7377 6762 ## F3D146_S212_L001_R1_001.fastq 5021 4580 ## F3D147_S213_L001_R1_001.fastq 17070 15695 ## F3D148_S214_L001_R1_001.fastq 12405 11448 ## F3D149_S215_L001_R1_001.fastq 13083 12064 ## F3D150_S216_L001_R1_001.fastq 5509 5054 ## F3D2_S190_L001_R1_001.fastq 19620 18130 ## F3D3_S191_L001_R1_001.fastq 6758 6275 ## F3D5_S193_L001_R1_001.fastq 4448 4068 ## F3D6_S194_L001_R1_001.fastq 7989 7394 ## F3D7_S195_L001_R1_001.fastq 5129 4772 ## F3D8_S196_L001_R1_001.fastq 5294 4890 ## F3D9_S197_L001_R1_001.fastq 7070 6525 ## Mock_S280_L001_R1_001.fastq 4779 4333 Wait for a while as your machine processing your request to trim and filter the amplicons. When it is done, the resulting amplicons will be located in the filtered_path you have stated earlier. You can track the number of in-and-out filtered reads for each sample in tnf_summary. 5.4 Infer Sequence Variants After filtering, typical workflow will continue to perform clustering of the DNA sequences into Operational Taxonomic Units (OTUs) or the estimated distinct species present in the community. This is performed by creating groups of sequencing reads that differ by less than a fixed dissimilarity threshhold. Even so, there is still a possibility of sequencing errors generating artificial sequences. To tackle this problem, a high-throughput DADA2 method was developed. This method can infer amplicon sequence variants (ASVs) from our amplicons data. ASVs are individual DNA sequences recovered after the removal of false sequences generated from error during PCR amplification and sequencing. ASVs are considered as the true biological sequences and therefore will be used for further analysis. DADA2 works by making use of a parametric error model err to distinguish between true biological sequences (ASVs) and those generated by error (Ben J. Callahan 2016). This error model learns the maximum possible error rates of our amplicons data using the learnErrors() function (Callahan, n.d.). The error model will later be used in the DADA2 algorithm using dada() function. # error model for forward reads error_F &lt;- learnErrors(filtered_F) #input: file path for filtered reads # error model for reverse reads error_R &lt;- learnErrors(filtered_R) # infer sequence variants dada_F &lt;- dada(filtered_F, err = error_F, verbose = FALSE) dada_R &lt;- dada(filtered_R, err = error_R, verbose = FALSE) Let’s check dada2 result from the first sample forward reads. Dada infer 130 true amplicon sequence variants from 1866 unique sequences. dada_F[1] ## $F3D0_F_filtered.fastq.gz ## dada-class: object describing DADA2 denoising results ## 130 sequence variants were inferred from 1866 input unique sequences. ## Key parameters: OMEGA_A = 1e-40, OMEGA_C = 1e-40, BAND_SIZE = 16 5.5 Merge Forward &amp; Reverse Reads The DADA2 algorithm removed (nearly) all substitution errors from the data and the data are now ready to be merged. merged &lt;- mergePairs(dadaF = dada_F, # dada result derepF = filtered_F, # path of filtered reads dadaR = dada_R, derepR = filtered_R) 5.6 Construct Sequence Table &amp; Remove Chimeras Using the merged pairs of the amplicon data, a sequence table or in this case an amplicon sequence variant (ASV) table can be generated. This table is in matrix format with rows stores the sample names and the columns stores the number of each ASVs. From this table we can inspect the number of ASVs (representing each microbial species) in each sample. ASV table is a higher-resolution version of the OTU table produced by tradisional method. We can construct a sequence table using makeSequenceTable(). seqtab &lt;- makeSequenceTable(merged) Below is a glimpse of what our seqtab matrix looks like: # first 3 observation; first 3 ASV (named by its DNA sequence) seqtab[1:3,1:3] ## GCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGTGCGCAGGCGGAAGATCAAGTCAGCGGTAAAATTGAGAGGCTCAACCTCTTCGAGCCGTTGAAACTGGTTTTCTTGAGTGAGCGAGAAGTATGCGGAATGCGTGGTGTAGCGGTGAAATGCATAGATATCACGCAGAACTCCGATTGCGAAGGCAGCATACCGGCGCTCAACTGACGCTCATGCACGAAAGTGTGGGT ## F3D0 582 ## F3D1 417 ## F3D141 442 ## GCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGTGCGCAGGCGGACTCTCAAGTCAGCGGTCAAATCGCGGGGCTCAACCCCGTTCCGCCGTTGAAACTGGGAGCCTTGAGTGCGCGAGAAGTAGGCGGAATGCGTGGTGTAGCGGTGAAATGCATAGATATCACGCAGAACTCCGATTGCGAAGGCAGCCTACCGGCGCGCAACTGACGCTCATGCACGAAAGCGTGGGT ## F3D0 345 ## F3D1 354 ## F3D141 363 ## GCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGTGCGTAGGCGGGCTGTTAAGTCAGCGGTCAAATGTCGGGGCTCAACCCCGGCCTGCCGTTGAAACTGGCGGCCTCGAGTGGGCGAGAAGTATGCGGAATGCGTGGTGTAGCGGTGAAATGCATAGATATCACGCAGAACTCCGATTGCGAAGGCAGCATACCGGCGCCCGACTGACGCTGAGGCACGAAAGCGTGGGT ## F3D0 451 ## F3D1 232 ## F3D141 347 We have three ASVs (sequences) and its number on each of our first three samples. For more tidy visualization, we can change the simplify the sample names: rownames(seqtab) &lt;- sample_names dim(seqtab) ## [1] 20 286 We have a total of maximum 286 ASVs or expected microbial species that may present in a community sample. The last data cleaning step that we can do is to remove chimeras. Chimeras are DNA sequences which are formed from 2 or more biological sequences joined together (Fig 4.2). These chimeras can act as distinct microbial species alone when in fact it is not a true microbial sequences. Chimeras can be identified if they can be exactly reconstructed by combining a left-segment and a right-segment from two more abundant “parent” or biological sequences. We can remove chimeras using function removeBimeraDenovo(). seqtab_nochim &lt;- removeBimeraDenovo(seqtab, method = &quot;consensus&quot;) dim(seqtab_nochim) ## [1] 20 234 Removing chimeras leave us with 234 ASVs from the original 286 ASVs we previously have. Even so, if you calculate the percentage of chimeric sequences from the total abundance of all sequences, it only accounts for 4% of the data. This amount is small and acceptable. On the other hand, if your analysis indicates a lot of chimeric sequences there might be some upstream processes that have gone wrong such as not removing the primer sequences from the fasta prior to reading the data (Callahan, n.d.). You can track the number of reads or sequences that made it through each step of the processes. # create function to get the sum of unique DNA getN &lt;- function(x) { sum(getUniques(x)) } # generate the summary track_reads &lt;- data.frame(row.names = sample_names, raw_reads = tnf_summary[,1], filtered = tnf_summary[,2], ASVs_F = sapply(dada_F, getN), # sapply to apply the function to all rows (sample) ASVs_R = sapply(dada_F, getN), joined = sapply(merged, getN), no_chimera = rowSums(seqtab_nochim)) # form row-column sums track_reads ## raw_reads filtered ASVs_F ASVs_R joined no_chimera ## F3D0 7793 7139 7021 7021 6667 6655 ## F3D1 5869 5314 5252 5252 5028 5028 ## F3D141 5958 5478 5369 5369 4995 4867 ## F3D142 3183 2926 2822 2822 2611 2546 ## F3D143 3178 2955 2837 2837 2598 2564 ## F3D144 4827 4323 4175 4175 3690 3540 ## F3D145 7377 6762 6622 6622 6150 5873 ## F3D146 5021 4580 4456 4456 4003 3901 ## F3D147 17070 15695 15505 15505 14080 12980 ## F3D148 12405 11448 11283 11283 10567 10027 ## F3D149 13083 12064 11917 11917 11166 10705 ## F3D150 5509 5054 4897 4897 4392 4306 ## F3D2 19620 18130 17977 17977 17520 16952 ## F3D3 6758 6275 6179 6179 5911 5611 ## F3D5 4448 4068 3932 3932 3723 3723 ## F3D6 7989 7394 7268 7268 6904 6716 ## F3D7 5129 4772 4657 4657 4435 4222 ## F3D8 5294 4890 4806 4806 4583 4553 ## F3D9 7070 6525 6397 6397 6154 6075 ## Mock 4779 4333 4309 4309 4292 4292 From the summary, we know that there is no over-large drop associated with any single step and we manage to keep majority of our data. Now we can move to the next step. 5.7 Assign Taxonomy Previous amplicon bioinformatics processes provide us with a sequence table containing the number of distinct amplicons (ASVs) which resembles a microbial species in each of our sample. This table will be more informative and easier to analyze when we have assign the taxonomy or identity for each ASVs in the table. That is like giving an identity to the considerably long ACGT-code in the into something more “readable” for the column names. Assigning taxonomy is a process of classifiying an unknown ASVs into a known microbial species. Using DADA2 package, it involves a native implementation of the naive Bayesian classifier method. The function assignTaxonomy() will take an input of a set of sequences to be classified (ASVs) and a training set of reference sequences with known taxonomy. The function will output taxonomic assinments for all ASVs with at least minBoot bootstrap confidence (parameter for the algorithm). Do it looks like a machine learning classification case? Yes, it is. There are various resources for training set fastas, but I will use the Silva reference database (McLaren 2020) for this example. To use it, go to this link and download these files: silva_nr_v138_train_set.fa.gz silva_species_assignment_v138.fa.gz and then place the files inside the same directory with our filtered sequences .fastq.gz files. We can then perform taxonomy assignment: # assign taxa until genus level taxa &lt;- assignTaxonomy(seqtab_nochim, # sequence table refFasta = &quot;data/filtered/silva_nr_v138_train_set.fa.gz&quot;, # reference sequence minBoot = 50) # minimal bootstrap confidence; default to 50 # add taxa until species level # note that it may result NA if there is no exact match in the reference taxa &lt;- addSpecies(taxa, # result from assignTaxonomy refFasta = &quot;data/filtered/silva_species_assignment_v138.fa.gz&quot;) # check taxonomic assignment taxa_print &lt;- taxa rownames(taxa_print) &lt;- NULL # for visualization purpose head(taxa_print) ## Kingdom Phylum Class Order Family ## [1,] &quot;Bacteria&quot; &quot;Bacteroidota&quot; &quot;Bacteroidia&quot; &quot;Bacteroidales&quot; &quot;Muribaculaceae&quot; ## [2,] &quot;Bacteria&quot; &quot;Bacteroidota&quot; &quot;Bacteroidia&quot; &quot;Bacteroidales&quot; &quot;Muribaculaceae&quot; ## [3,] &quot;Bacteria&quot; &quot;Bacteroidota&quot; &quot;Bacteroidia&quot; &quot;Bacteroidales&quot; &quot;Muribaculaceae&quot; ## [4,] &quot;Bacteria&quot; &quot;Bacteroidota&quot; &quot;Bacteroidia&quot; &quot;Bacteroidales&quot; &quot;Muribaculaceae&quot; ## [5,] &quot;Bacteria&quot; &quot;Bacteroidota&quot; &quot;Bacteroidia&quot; &quot;Bacteroidales&quot; &quot;Bacteroidaceae&quot; ## [6,] &quot;Bacteria&quot; &quot;Bacteroidota&quot; &quot;Bacteroidia&quot; &quot;Bacteroidales&quot; &quot;Muribaculaceae&quot; ## Genus Species ## [1,] NA NA ## [2,] NA NA ## [3,] NA NA ## [4,] NA NA ## [5,] &quot;Bacteroides&quot; NA ## [6,] NA NA For those of you who were more exposed to the manual approach of assigning taxonomy (using BLAST and then performing multiple sequence alignment for all the microbes being targeted)–like me in my university years, you must be quite confused with this new classification approach. But using this new algorithm to perform massive taxonomy assignments on numerous unknown species simultaneously is considered a common approach now. Personally, I captured this as a solid movement towards the rising of Big Data era in Biology, just like the data we use in this book. In this point, you can additionally check the accuracy of DADA2 algorithm in inferring sequence variants by comparing the result of mock samples to the annotated sequence of mock samples HMP_mock.v35 fasta. I’ll leave it for you to explore the original documentation here. 5.8 Construct Phylogenetic Tree Phylogenetic relatedness is commonly used to inform downstream analyses, especially the calculation of phylogenyaware distances between microbial communities, such as when plotting multivariate projection among samples. We begin constructing phylogenetic tree by performing a multiple-alignment using the DECIPHER package (Ben J. Callahan 2016). # obtain sequence seqs &lt;- getSequences(seqtab_nochim) names(seqs) &lt;- seqs # This propagates to the tip labels of the tree # do msa alignment &lt;- AlignSeqs(DNAStringSet(seqs), anchor=NA) The phangorn package is then used to construct a phylogenetic tree. Here we first construct a neighbor-joining tree, and then fit a GTR+G+I (Generalized time-reversible with Gamma rate variation) maximum likelihood tree using the neighbor-joining tree as a starting point (Ben J. Callahan 2016). phang.align &lt;- phyDat(as(alignment, &quot;matrix&quot;), type=&quot;DNA&quot;) # converting into phyDat format dm &lt;- dist.ml(phang.align) # compute pairwaise distances treeNJ &lt;- NJ(dm) # construct neighbor-joining tree fit &lt;- pml(treeNJ, data = phang.align) # computes likelihood of phylogenetic tree fitGTR &lt;- update(fit, k=4, inv=0.2) # re-fit a model fitGTR &lt;- optim.pml(fitGTR, model=&quot;GTR&quot;, optInv=TRUE, optGamma=TRUE, rearrangement = &quot;stochastic&quot;, control = pml.control(trace = 0)) 5.9 Create Phyloseq Object After many process of amplicon bioinformatics, the last thing we can do is to combine all the processed data into a phyloseq object. A phyloseq object will contain all the processed raw data in a bundle, which will be easier for us to manipulate for microbiome analysis. We can create a phylosec object by combining several metadata and the result of our DADA2 process. We will use the sample names which stores the information. Keep in mind that we have to pay attention to where is the mock sample is located for it has different naming system and therefore needs special treatments. sample_names ## [1] &quot;F3D0&quot; &quot;F3D1&quot; &quot;F3D141&quot; &quot;F3D142&quot; &quot;F3D143&quot; &quot;F3D144&quot; &quot;F3D145&quot; &quot;F3D146&quot; ## [9] &quot;F3D147&quot; &quot;F3D148&quot; &quot;F3D149&quot; &quot;F3D150&quot; &quot;F3D2&quot; &quot;F3D3&quot; &quot;F3D5&quot; &quot;F3D6&quot; ## [17] &quot;F3D7&quot; &quot;F3D8&quot; &quot;F3D9&quot; &quot;Mock&quot; Below we will extract the information one by one: gender &lt;- substr(sample_names, start = 1, stop = 1) # get the first character gender ## [1] &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; ## [20] &quot;M&quot; subject &lt;- substr(sample_names, 2, 2) # get the second character subject ## [1] &quot;3&quot; &quot;3&quot; &quot;3&quot; &quot;3&quot; &quot;3&quot; &quot;3&quot; &quot;3&quot; &quot;3&quot; &quot;3&quot; &quot;3&quot; &quot;3&quot; &quot;3&quot; &quot;3&quot; &quot;3&quot; &quot;3&quot; &quot;3&quot; &quot;3&quot; &quot;3&quot; &quot;3&quot; ## [20] &quot;o&quot; day &lt;- sapply(strsplit(sample_names, &quot;D&quot;), `[`, 2) %&gt;% # separate by &#39;D&#39;; get the 2nd value [2] as.integer() # convert to integer day ## [1] 0 1 141 142 143 144 145 146 147 148 149 150 2 3 5 6 7 8 9 ## [20] NA # combine metadata seq_data &lt;- data.frame(Subject = subject, Gender = gender, Day = day, When = ifelse(day &lt; 100, &quot;Early&quot;, &quot;Late&quot;), # add early/late sampling period row.names = sample_names) head(seq_data) ## Subject Gender Day When ## F3D0 3 F 0 Early ## F3D1 3 F 1 Early ## F3D141 3 F 141 Late ## F3D142 3 F 142 Late ## F3D143 3 F 143 Late ## F3D144 3 F 144 Late Now let’s create a phylosec object: # create phylosec object ps &lt;- phyloseq(otu_table(seqtab_nochim, taxa_are_rows=FALSE), sample_data(seq_data), tax_table(taxa), phy_tree(fitGTR$tree)) # remove mock sample ps &lt;- prune_samples(sample_names(ps) != &quot;Mock&quot;, ps) ps ## phyloseq-class experiment-level object ## otu_table() OTU Table: [ 234 taxa and 19 samples ] ## sample_data() Sample Data: [ 19 samples by 4 sample variables ] ## tax_table() Taxonomy Table: [ 234 taxa by 7 taxonomic ranks ] ## phy_tree() Phylogenetic Tree: [ 234 tips and 232 internal nodes ] ## refseq() DNAStringSet: [ 234 reference sequences ] It is also better to merge the sequences of our ASVs in the phyloseq object. We will use function from Biostrings package to extract sequences from ASV table. The sequences are stored as taxa names in ASVs table (labelled as OTU table). # get sequences dna &lt;- Biostrings::DNAStringSet(taxa_names(ps)) names(dna) &lt;- taxa_names(ps) # connect dna data to taxa names dna ## DNAStringSet object of length 234: ## width seq names ## [1] 232 GCGAGCGTTATCCGGATTTATT...GCTCATGCACGAAAGTGTGGGT GCGAGCGTTATCCGGAT... ## [2] 232 GCGAGCGTTATCCGGATTTATT...GCTCATGCACGAAAGCGTGGGT GCGAGCGTTATCCGGAT... ## [3] 232 GCGAGCGTTATCCGGATTTATT...GCTGAGGCACGAAAGCGTGGGT GCGAGCGTTATCCGGAT... ## [4] 232 GCGAGCGTTATCCGGATTTATT...GCTGAGGCACGAAAGTGCGGGG GCGAGCGTTATCCGGAT... ## [5] 233 CCGAGCGTTATCCGGATTTATT...ACTGATGCTCGAAAGTGTGGGT CCGAGCGTTATCCGGAT... ## ... ... ... ## [230] 233 GCAAGCGTTATCCGGAATGACT...ACTGAGGCACGAAAGCGTGGGG GCAAGCGTTATCCGGAA... ## [231] 233 GCGAGCGTTATCCGGATTTATT...GTTGAGGCACGAAAGTGTGGGG GCGAGCGTTATCCGGAT... ## [232] 232 GCGAGCGTTATCCGGATTCATT...GCTGAGGCGCGAAAGCTGGGGG GCGAGCGTTATCCGGAT... ## [233] 232 GCGAGCGTTATCCGGATTCATT...GCTGAGGCGCGAAAGCTAGGGG GCGAGCGTTATCCGGAT... ## [234] 232 GCGAGCGTTATCCGGATTTATT...GCTGAGGCACGAAAGCGTGGGG GCGAGCGTTATCCGGAT... # merge data ps &lt;- merge_phyloseq(ps, dna) # change taxa names into shorter id (ASVn) taxa_names(ps) &lt;- paste0(&quot;ASV&quot;, seq(ntaxa(ps))) Now, we can easily retrieve DNA sequences for each ASVs using taxa names as key id. # first three ASVs in our samples otu_table(ps)[,1:3] ## OTU Table: [3 taxa and 19 samples] ## taxa are columns ## ASV1 ASV2 ASV3 ## F3D0 582 345 451 ## F3D1 417 354 232 ## F3D141 442 363 347 ## F3D142 290 305 159 ## F3D143 231 176 204 ## F3D144 424 277 304 ## F3D145 647 494 523 ## F3D146 326 231 254 ## F3D147 1499 1220 913 ## F3D148 870 732 580 ## F3D149 887 781 725 ## F3D150 318 232 402 ## F3D2 3509 1594 1179 ## F3D3 998 606 469 ## F3D5 322 265 284 ## F3D6 1017 675 590 ## F3D7 649 504 439 ## F3D8 277 356 352 ## F3D9 512 426 485 # first 3 ASVs sequences refseq(ps)[1:3] ## DNAStringSet object of length 3: ## width seq names ## [1] 232 GCGAGCGTTATCCGGATTTATTG...CGCTCATGCACGAAAGTGTGGGT ASV1 ## [2] 232 GCGAGCGTTATCCGGATTTATTG...CGCTCATGCACGAAAGCGTGGGT ASV2 ## [3] 232 GCGAGCGTTATCCGGATTTATTG...CGCTGAGGCACGAAAGCGTGGGT ASV3 We finally have our final phyloseq object containing ASVs table, our sample metadata, taxonomy table for our ASVs, and its DNA sequences. ps ## phyloseq-class experiment-level object ## otu_table() OTU Table: [ 234 taxa and 19 samples ] ## sample_data() Sample Data: [ 19 samples by 4 sample variables ] ## tax_table() Taxonomy Table: [ 234 taxa by 7 taxonomic ranks ] ## phy_tree() Phylogenetic Tree: [ 234 tips and 232 internal nodes ] ## refseq() DNAStringSet: [ 234 reference sequences ] # this is the code incase you want to save the phyloseq object: # saveRDS(ps, file = &quot;assets/05/ps.RDS&quot;) After creating the phylosec object, we are ready to dive deeper into microbiome analysis in the next chapter! "],
["phyloseq-object-processing.html", "Chapter 6 Phyloseq Object Processing 6.1 Filtering 6.2 Agglomerate Taxa", " Chapter 6 Phyloseq Object Processing Microbiome analysis comes with many challenging tasks. It involves the integration of various types of data with methods from ecology, genetics, network analysis and visualization. The data itself may originate from widely different sources such as humans, animals, samples from environment including industrial and public facilities. This variety result in data with various forms and scales, making the data processing steps extremely dependent upon the experiment and its question(s). The phyloseq package offers tools to import, store, analyze and graphically display complex phylogenetic sequencing data. It leverages many packages available in R for ecology and phylogenetic analysis (vegan, ade4, ape, picante) while also using flexible graphic system for visualization using ggplot2 package McMurdie (n.d.). Phyloseq accepts many forms of microbiome data, including QIIME format. But in this tutorial, following the previous step, we will use the phyloseq object ps we have made earlier. It already contains our sequence table and its supplementary data. We are going to perform several data pre-processing: Filtering: Taxonomic Filtering Agglomerate Taxa # load phyloseq object `ps` if you haven&#39;t # ps &lt;- readRDS(&quot;assets/05/ps.rds&quot;) 6.1 Filtering One of the reasons to filter microbiome data is to avoid spending much time analyzing taxa that were seen only rarely among samples. There are two kinds of filtering, taxonomic and prevalence filtering. In this example, we will use the taxonomic filtering that is quite supervised and relies on taxonomic assignment (it is supervised because it relies on taxonomic reference database). Even so, if you are quite curious about the later one, you can read the more detailed tutorial in here. In brief, prevalence filtering is the type of filtering that is more unsupervised. It relies on the relationship between prevalence of taxa and total abundance of each samples, hoping that the pattern reveals outliers that should probably be removed. This filtering is most applicable when taxonomic annotation is unavailable or unreliable. In most biological settings, the organisms present in all samples are well-represented in the available taxonomic reference database. With this assumption, it is advisable to filter organisms which its high-rank taxonomy could not be assigned. Thise organism (sequence) are almost always sequence artifacts that don’t exist in nature. For this, Phylum is a useful taxonomic for filtering, although other options are possible for your own research. # possible taxonomic rank rank_names(ps) ## [1] &quot;Kingdom&quot; &quot;Phylum&quot; &quot;Class&quot; &quot;Order&quot; &quot;Family&quot; &quot;Genus&quot; &quot;Species&quot; In our ps data, we have a tax_table which stores taxonomic assignment for each of our 234 ASVs (organisms), stored in matrix format. We can access that through tax_table() and ensure its dimension. # rows - column: 234 ASVs - 7 Taxonomic Rank dim(tax_table(ps)) ## [1] 234 7 Now, let’s calculate the number of organisms present for each Phylum. table(tax_table(ps)[,&quot;Phylum&quot;]) ## ## Actinobacteriota Bacteroidota Campilobacterota Cyanobacteria ## 7 20 1 3 ## Deinococcota Firmicutes Patescibacteria Proteobacteria ## 1 193 1 7 ## Verrucomicrobiota ## 1 Based on the table above there is no that indicates a sequece artifacts. We can go on to the next step. 6.2 Agglomerate Taxa When there is known to be a lot of species or sub-species redundancy in a microbial community, it might be useful to agglomerate or if I say “bundle” the data (taxonomy) into the closely related taxa. While not necessarily the most useful or functionally-accurate criteria for grouping microbial features (sometimes far from accurate), taxonomic agglomeration has the advantage of being much easier to define ahead of time Ben J. Callahan (2016). The following code shows how we would “bundle” all organisms descend from the same genus. # available genus: 49 (not including NA) get_taxa_unique(ps, taxonomic.rank = &quot;Genus&quot;) ## [1] NA &quot;Bacteroides&quot; ## [3] &quot;Alistipes&quot; &quot;Lactobacillus&quot; ## [5] &quot;Turicibacter&quot; &quot;Lachnospiraceae_NK4A136_group&quot; ## [7] &quot;Oscillibacter&quot; &quot;Eisenbergiella&quot; ## [9] &quot;Staphylococcus&quot; &quot;A2&quot; ## [11] &quot;Acinetobacter&quot; &quot;Roseburia&quot; ## [13] &quot;Lachnoclostridium&quot; &quot;Bacillus&quot; ## [15] &quot;Incertae_Sedis&quot; &quot;Lachnospiraceae_UCG-001&quot; ## [17] &quot;Helicobacter&quot; &quot;Anaeroplasma&quot; ## [19] &quot;Actinomyces&quot; &quot;Clostridium_sensu_stricto_1&quot; ## [21] &quot;Neisseria&quot; &quot;Bifidobacterium&quot; ## [23] &quot;Acetatifactor&quot; &quot;Lachnospiraceae_UCG-004&quot; ## [25] &quot;Streptococcus&quot; &quot;Lachnospiraceae_FCS020_group&quot; ## [27] &quot;Escherichia/Shigella&quot; &quot;Candidatus_Saccharimonas&quot; ## [29] &quot;Enterococcus&quot; &quot;Colidextribacter&quot; ## [31] &quot;Anaerotruncus&quot; &quot;Listeria&quot; ## [33] &quot;Lachnospiraceae_UCG-006&quot; &quot;Pseudomonas&quot; ## [35] &quot;Deinococcus&quot; &quot;Porphyromonas&quot; ## [37] &quot;Herbinix&quot; &quot;ASF356&quot; ## [39] &quot;GCA-900066575&quot; &quot;Rhodobacter&quot; ## [41] &quot;Family_XIII_UCG-001&quot; &quot;Enterorhabdus&quot; ## [43] &quot;Tyzzerella&quot; &quot;Intestinimonas&quot; ## [45] &quot;Butyricicoccus&quot; &quot;Akkermansia&quot; ## [47] &quot;Candidatus_Arthromitus&quot; &quot;UCG-005&quot; ## [49] &quot;Lachnospiraceae_NK4B4_group&quot; &quot;Olsenella&quot; # agglomerate taxa ps_agg &lt;- tax_glom(ps, &quot;Genus&quot;, NArm = TRUE) Note that the parameter NArm = TRUE removes unassigned sequence on Genus. But be caution of this! This choice is very dependent on your research case and can really affect the downstream or following analysis. Below is our original and agglomerated data and their phylogenetic tree. Note that the tree from the agglomerated data is more simpler and will be much more easier to interpret later (if we need one for phylogenetic analysis, although we will not discuss much in this tutorial). I personally think that the taxonomy rank “Genus” is decent enough to identify an originally unknown microbial species. # original data ps ## phyloseq-class experiment-level object ## otu_table() OTU Table: [ 234 taxa and 19 samples ] ## sample_data() Sample Data: [ 19 samples by 4 sample variables ] ## tax_table() Taxonomy Table: [ 234 taxa by 7 taxonomic ranks ] ## phy_tree() Phylogenetic Tree: [ 234 tips and 232 internal nodes ] ## refseq() DNAStringSet: [ 234 reference sequences ] # agglomerated data ps_agg ## phyloseq-class experiment-level object ## otu_table() OTU Table: [ 49 taxa and 19 samples ] ## sample_data() Sample Data: [ 19 samples by 4 sample variables ] ## tax_table() Taxonomy Table: [ 49 taxa by 7 taxonomic ranks ] ## phy_tree() Phylogenetic Tree: [ 49 tips and 48 internal nodes ] ## refseq() DNAStringSet: [ 49 reference sequences ] ps_tree &lt;- plot_tree(ps, method = &quot;treeonly&quot;, ladderize = &quot;left&quot;, title = &quot;Before Agglomeration&quot;) ps_agg_tree &lt;- plot_tree(ps_agg, method = &quot;treeonly&quot;, ladderize = &quot;left&quot;, title = &quot;After Agglomeration&quot;) ps_tree ps_agg_tree We have completely perform data pre-processing. Let’s use this pre-processed data into further exploratory data analysis using plots and multivariate projections method such as PCoA. "],
["microbiome-analysis.html", "Chapter 7 Microbiome Analysis 7.1 Multivariate Projection 7.2 Microbial Abundandce", " Chapter 7 Microbiome Analysis Exploratory Data Analysis is perhaps the most insightful step we can do during microbiome analysis. It usually aims to discover patterns that may best distinguish and explain the data. Exploratory Data Analysis utilize visualization of the data by using common plots and multivariate projections such as PCoA. 7.1 Multivariate Projection The first explanatory data analysis we will do is to perform multivariate projection of our sample data. This is to discover pattern that might best distinguish our data and use it for further analysis. Before visualization, it is common to normalize our data. We can use transform_sample_counts() to define our specific function. In this example, we will log-transform our original abundance data as an approximate variance stabilizing transformation Ben J. Callahan (2016). We will use column When from sample data to annotate plots. # log-transform data ps_log &lt;- transform_sample_counts(ps_agg, function(x) log(1 + x)) # making ordinate out_wuf_log &lt;- ordinate(ps_log, method = &quot;MDS&quot;, # for PCoA distance = &quot;wunifrac&quot;) # weighted Unifrac distance # prepare eigen values to adjust axis evals &lt;- out_wuf_log$values$Eigenvalues plot_pcoa&lt;- plot_ordination(ps_log, out_wuf_log, color = &quot;When&quot;) + geom_text(aes(label = sample_names(ps_log)), size = 3, nudge_y = 0.02) + labs(col = &quot;Sampling Period&quot;) + # to adjust axis length based on eigen values (variance it contains) coord_fixed(sqrt(evals[2] / evals[1])) plot_pcoa Based on the plot above, it is becoming more clear that there is a difference between microbial community came from the early and late sampling period. Refering back to our research question, “the mice gut microbiome on the 10 days of post weaning (eating) period did encounter a shift/changes when we compared it to its late period”. But what are the changes? This can be explored more by plotting microbial abundance of our samples. Besides discovering patterns, PCoA plot also useful for telling us whether there are outliers in our data. From the plot above, the sample F3D142 seems to be an outlier. We can remove the data before further analysis. ps_cut &lt;- prune_samples(sample_names(ps_agg) != &quot;F3D142&quot;, ps_agg) 7.2 Microbial Abundandce The next explanatory data analysis we will do is to check the microbial abundance within each sample (microbial sequence count per sample). Before visualization, it is common to normalize our abundance data. Same as before, we can use transform_sample_counts() to define our specific function. In this example, we will converts the microbial count stored in the ps_cut into frequencies per total count for each sample a.k.a proportions or relative abundance. ps_relav &lt;- transform_sample_counts(ps_cut, function(x){x / sum(x)}) Here’s our abundance data before and after transformation: # before transformation ps_cut@otu_table[1:6, 1:3] ## OTU Table: [3 taxa and 6 samples] ## taxa are columns ## ASV5 ASV8 ASV11 ## F3D0 173 185 111 ## F3D1 140 191 284 ## F3D141 190 324 225 ## F3D143 130 84 134 ## F3D144 105 41 332 ## F3D145 308 126 388 # inspect data after ps_relav@otu_table[1:6, 1:3] ## OTU Table: [3 taxa and 6 samples] ## taxa are columns ## ASV5 ASV8 ASV11 ## F3D0 0.06995552 0.07480793 0.04488476 ## F3D1 0.05513982 0.07522647 0.11185506 ## F3D141 0.13868613 0.23649635 0.16423358 ## F3D143 0.19877676 0.12844037 0.20489297 ## F3D144 0.11972634 0.04675029 0.37856328 ## F3D145 0.24463860 0.10007943 0.30818110 In plotting microbial abundance it is best to follow our original research question, something that we really want to analyze. Like before, let’s plot the microbial abundance per sampling period. This information can support our analysis on our research question: We want to understand the effect of the first 10 days of post weaning (eating) period to the stability of gut microbiome in the 140-150 day of post weaning period. Now let’s plot our microbial abundace data using a DIY function. The function will result in microbial abundance per taxonomical rank we provided for each categorical features we ought to analyze. Here are a list of Phylum taxonomical rank that we can analyze from the sample: # convert to data frame for easier access tax_table &lt;- as.data.frame(ps_relav@tax_table@.Data) # phylum unique(tax_table$Phylum) ## [1] &quot;Bacteroidota&quot; &quot;Firmicutes&quot; &quot;Proteobacteria&quot; ## [4] &quot;Campilobacterota&quot; &quot;Actinobacteriota&quot; &quot;Patescibacteria&quot; ## [7] &quot;Deinococcota&quot; &quot;Verrucomicrobiota&quot; Note that in this tutorial, we only have the categorical features Day or When which stands for the day of sampling period. ps_relav@sam_data ## Subject Gender Day When ## F3D0 3 F 0 Early ## F3D1 3 F 1 Early ## F3D141 3 F 141 Late ## F3D143 3 F 143 Late ## F3D144 3 F 144 Late ## F3D145 3 F 145 Late ## F3D146 3 F 146 Late ## F3D147 3 F 147 Late ## F3D148 3 F 148 Late ## F3D149 3 F 149 Late ## F3D150 3 F 150 Late ## F3D2 3 F 2 Early ## F3D3 3 F 3 Early ## F3D5 3 F 5 Early ## F3D6 3 F 6 Early ## F3D7 3 F 7 Early ## F3D8 3 F 8 Early ## F3D9 3 F 9 Early It is sufficient enough for our research question, therefore we’ll use that for analysis. But if your sample has more features to explore, you can explore it as much as you want with the DIY function below! Note that the DIY function will use functions from ggplot2 package so make sure you have loaded it into your session. # DIY function plot_abundance &lt;- function(x = physeq, # phyloseq data title = &quot;&quot;, Facet = &quot;Phylum&quot;, # taxa rank for facets Category = &quot;When&quot;, # categorical features for x axis Color = &quot;Phylum&quot;, legend = &quot;none&quot; ) { mphyseq &lt;- psmelt(x) mphyseq &lt;- subset(mphyseq, Abundance &gt; 0) ggplot(data = mphyseq, mapping = aes_string(x = Category, y = &quot;Abundance&quot;, color = Color, fill = Color) ) + geom_violin(fill = NA) + geom_point(size = 1, alpha = 0.3, position = position_jitter(width = 0.3)) + facet_wrap(facets = Facet, ncol = 3) + scale_y_log10() + labs(title = title) + theme(legend.position = legend) } # plotting abundance plot &lt;- plot_abundance(ps_relav, &quot;Microbial Abundance on All Phylum&quot;) plot The combined jitter and density plot above shown how each microbes (point) present in our samples based on its relative abundance for both early and late sampling period. The wider the size of a violin plot, the higher frequencies or possibility of our sample having that score of abundance. Based on the jitter visualization, we know that the Phylum Firmicutes dominates the mice gut microbiome compared to other taxa. That means the microbes present in the mice gut mostly comes from the Phylum Firmicutes, and then accompanied by some other microbes from the Phylum Bacteroidota, Actinobacteria, Patescibacteria, and Proteobacteria. Although Firmicutes dominates the diversity of the mice gut microbiome, the violin plots also revealed that its abundance is highly varied from low to high abundance. Compared to Bacteroidota which, although only having some microbial species present in our sample, most of the species have a high abundance in our sample. Meanwhile, Actinobacteria, Patescibacteria and Proteobacteria present in a more lower abundance. Another thing we can take from the plot is that the microbial community is slightly changing from the early to the late period of mice age. You can see that Firmicutes and Bacteriodota sligtly having lower abundance in its late period than its early one, and Actinobacteria which has slightly higher abundance in its late period. By combining this microbial abundance and diversity data with the metabolic activities the microbiome can do (what kind of chemicals it can produce or consume in the gut) we may actually derive some insight on how the gut microbiome can affect the mice metabolic activity or even health. You can try to detail the diversity even more. Below is the code to plot a more detailed plot, for only the Phylum Firmicutes. plot_ordo &lt;- plot_abundance(ps_relav, title = &quot;Microbial Abundance on Firmicutes&quot;, Facet = &quot;Order&quot;) plot_ordo From the plot above we know that among Firmicutes, the Order Acholeplasmatales, Clostridiales, Enterobacterales, Erysipelotrichales,, Lactobacillales, and Oscillospirales are some microbes that the abundace are different between early and late samples. Perhaps it can be used to distinguish between mice in its early age or in its late age. Additionally, phyloseq also provides other plot types commonly used to plot microbial abundance data. Such as this abundance bar plot below: plot2 &lt;- plot_bar(ps_relav, fill = &quot;Phylum&quot;, x = &quot;reorder(Sample, Day)&quot;) plot2 For more functions and visualization, you can go directly to the official demo page here. "],
["classification-using-microbiome.html", "Chapter 8 Classification using Microbiome", " Chapter 8 Classification using Microbiome The main microbiome analysis was already done in the previous chapter. But the result of previous chapter can be used further for additional analysis. In this capter we will demonstrate examples for doing supervised learning (a classification task) using microbiome data. The classification task enhanced by microbiome data relies on the sample we have, which was obtained based on a research question. Our research question provide a design where we can obtain sample from early or old aged mouse. After microbiome analysis, we knew that microbiome composition change with age. Therefore, we can try classify whether a mouse is early or old aged based on the its gut microbioal composition. The package caret provides various functions for machine learning algorithm. We’ll try using the robust Random Forest algorithm on this one. For that we also need a randomForest package. Make sure that you have each of them installed and loaded into your session. # load library library(caret) library(randomForest) We’ll be using microbial count or otu_table from ps_cut data which represent the microbial composition of our sample. This data is also already removed for its outlier. We’ll also log-transform our data before analysis. ps_cut@otu_table[1:3,1:3] ## Loading required package: phyloseq ## OTU Table: [3 taxa and 3 samples] ## taxa are columns ## ASV5 ASV8 ASV11 ## F3D0 173 185 111 ## F3D1 140 191 284 ## F3D141 190 324 225 ps_cut_log &lt;- transform_sample_counts(ps_cut, function(x) log(1 + x)) ps_cut_log@otu_table[1:3,1:3] ## OTU Table: [3 taxa and 3 samples] ## taxa are columns ## ASV5 ASV8 ASV11 ## F3D0 5.159055 5.225747 4.718499 ## F3D1 4.948760 5.257495 5.652489 ## F3D141 5.252273 5.783825 5.420535 The first step of classification (or any machine learning task) is to divide our data into train and test set. to ensure that the test set realistically simulates the collection of new data, we will be using random sampling to split the data. # get age label &amp; microbiome data data_ml &lt;- data.frame(age = sample_data(ps_cut_log)$When, otu_table(ps_cut_log)) # get index for sampling idx_train &lt;- sample(nrow(sample_data(ps_cut_log)), size = nrow(sample_data(ps_cut_log))*0.8) # splitting train-test training &lt;- data_ml[idx_train,] testing &lt;- data_ml[-idx_train,] Once we split the data, we can use the train function to fit the Random Forest model. rfFit &lt;- train(age ~ ., data = training, method = &quot;rf&quot;) rfFit table(rfClasses, testing$age) ## ## rfClasses Early Late ## Early 2 0 ## Late 0 2 Next we can predict mouse age labels on the test set using predict() function. rfClasses &lt;- predict(rfFit, newdata = testing) Then we can do a quick model evaluation by using simple confusion matrix. # other options use: `confusionMatrix()` table(pred = rfClasses, actual = testing$age) ## actual ## pred Early Late ## Early 2 0 ## Late 0 2 We’ll there is accuracy 100%, but please note that the number of data we have for this demonstration is still very low. It might be better to train and test the model with a larger sample size, for example 30-300 sample or more. To better understand the fitted random forest model, we can identify which microbe have the highest influence in the random forest prediction. We can use the function importance() from randomForest package and to find out each variable or in our case microbial species importance: importance(rfFit$finalModel) ## MeanDecreaseGini ## ASV5 0.125397702 ## ASV8 0.219382928 ## ASV11 0.163005528 ## ASV15 0.271417316 ## ASV16 0.333647808 ## ASV27 0.405051571 ## ASV30 0.239835786 ## ASV34 0.000000000 ## ASV41 0.148721834 ## ASV44 0.014960373 ## ASV45 0.141743723 ## ASV46 0.165285570 ## ASV47 0.000000000 ## ASV48 0.147208791 ## ASV52 0.255870751 ## ASV53 0.000000000 ## ASV58 0.242872006 ## ASV60 0.000000000 ## ASV65 0.086742524 ## ASV66 0.280912821 ## ASV68 0.301280131 ## ASV71 0.117645455 ## ASV74 0.306883006 ## ASV81 0.175225974 ## ASV86 0.069356466 ## ASV89 0.106354057 ## ASV92 0.000000000 ## ASV94 0.131035786 ## ASV99 0.268397036 ## ASV101 0.000000000 ## ASV102 0.087275169 ## ASV111 0.016042025 ## ASV120 0.000000000 ## ASV121 0.163664924 ## ASV132 0.221767621 ## ASV141 0.240852081 ## ASV143 0.103141114 ## ASV145 0.000000000 ## ASV146 0.058373826 ## ASV164 0.098591275 ## ASV172 0.070926607 ## ASV177 0.068640637 ## ASV190 0.024858841 ## ASV191 0.008968032 ## ASV203 0.063437085 ## ASV208 0.026504762 ## ASV217 0.010176623 ## ASV224 0.023548452 ## ASV233 0.029568909 The function above shown all the variable importance, but we only need one microbe with the highest importance. In this case “ASV27”. Let’s use some function to simply take out that microbe and find out its taxonomy so we can analyze it further. # obtain taxonomy of all microbial sample tax_rf &lt;- tax_table(ps_cut_log) # filter microbes with the highest importance tax_rf[which.max(importance(rfFit$finalModel)),] ## Taxonomy Table: [1 taxa by 7 taxonomic ranks]: ## Kingdom Phylum Class Order Family ## ASV27 &quot;Bacteria&quot; &quot;Firmicutes&quot; &quot;Clostridia&quot; &quot;Oscillospirales&quot; &quot;Oscillospiraceae&quot; ## Genus Species ## ASV27 &quot;Oscillibacter&quot; NA This turns out to be a microbe from Orer Oscillospirales, Family Oscillospiraceae, and genus Oscillibacter. Let’s try plots its abundance across samples. # get microbial abundance imp_abd &lt;- as.vector(otu_table(ps_cut_log)[,&quot;ASV27&quot;]) # combine with sample data imp_df &lt;- data.frame(sample_data(ps_cut_log), abund = imp_abd) # plotting imp_plot&lt;- ggplot(imp_df, aes(x = abund)) + geom_density(aes(fill = When), alpha = 0.5) + labs(title = &quot;Abundance of Discriminative Species&quot;, subtitle = &quot;Oscillibacter sp.&quot;, x = &quot;Abundance&quot;, y = &quot;Density of samples&quot;, fill = &quot;Age&quot;) + # below is for aesthetics theme_minimal() imp_plot We can see that Oscillibacter sp. has lower abundance in the mouse early age (0-9 days) and much higher in its late age (141-150). Based on this research, Oscillibacter sp. may become a biomarker for mouse age for classification task. "],
["closure.html", "Chapter 9 Closure", " Chapter 9 Closure We finally finished our brief journey on the exploration of microbiome analysis in R. Although our data is only a few, the tutorial hopefully have demonstrated many of the steps and main options of microbial analysis you can do in R. We have started with the aim to analyze whether the gut microbiome changes or differ between the early and late days of post weaning (eating) period of a mice, using the data mothur MiSeq SOP. The analysis showed that there is a difference between in the gut microbiome composition between the early and late samples. We also knew that the gut microbiome was dominated by microbes from the phylum Firmicutes, and among them the microbe Oscillibacter sp. became the most important microbes in differentiating between the early and late aged mice using Random Forest algorithm. There is much more you can explore about microbiome analysis in R. There is even a new package on development also for microbiome analysis, called microbiome. I have made a mini article about it also in here, but hopefully I am able to update it to give it a more detailed touch. Even so, this book hopefully compromise a decent overview, step-by-step, from raw reads to insight, overall aspect of microbiome analysis in R. Thank you for reading and I hope this book has been useful to you! Keep learning and exploring! "],
["references.html", "Chapter 10 References", " Chapter 10 References "]
]
